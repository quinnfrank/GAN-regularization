{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN Implementation\n",
    "\n",
    "Implementation of the (vanilla) Deep Convolutional Generative Adversarial Network defined by <a href=\"https://arxiv.org/pdf/1511.06434.pdf\">Radford, Metz, and Chintala (2016)</a>.  Testing is done on the <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">CIFAR-10</a> benchmark image dataset, stored in pickled format in the `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions to convert CIFAR-10 to Pytorch Dataset\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as in_file:\n",
    "        pickle_dict = pickle.load(in_file, encoding='bytes')\n",
    "    return pickle_dict\n",
    "\n",
    "\n",
    "def read_data(file_name):\n",
    "    \"\"\"Given path to CIFAR data batch, returns raw X, y tensors.\"\"\"\n",
    "    \n",
    "    batch_dict = unpickle(file_name)\n",
    "    X_raw = torch.tensor(batch_dict[b'data'])\n",
    "    y_raw = torch.tensor(batch_dict[b'labels']).long()\n",
    "    return X_raw, y_raw\n",
    "\n",
    "\n",
    "def shape_image(X):\n",
    "    \"\"\"Reshapes raw data tensor to nn.module-compatible RGB image\"\"\"\n",
    "    \n",
    "    # Each row of X_raw contains RGB color channels concatenated in row-major order\n",
    "    # Need to first split channels into dim 1 on tensor, then shape dim 2/3 into image\n",
    "    image_size = 32*32\n",
    "    X = torch.split(X.unsqueeze(dim=1), image_size, dim=2)\n",
    "    X = torch.cat(X, dim=1)\n",
    "    X = X.view(-1, 3, 32, 32)   # (N, channels, pixel rows, pixel cols)\n",
    "    return X\n",
    "\n",
    "\n",
    "def normalize(X, a=-1, b=1):\n",
    "    \"\"\"Normalizes data tensor to [a, b] using min-max scaling.\"\"\"\n",
    "    \n",
    "    data_min = torch.min(X).float().item()\n",
    "    data_max = torch.max(X).float().item()\n",
    "    assert a < b, \"Rescaled range [a, b] must have a < b\"\n",
    "    \n",
    "    # First scale to [0, 1], then rescale to [a, b]\n",
    "    X = (X - data_min) / (data_max - data_min)\n",
    "    X = (X * (b - a)) + a  \n",
    "    return X\n",
    "\n",
    "\n",
    "class CIFARDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Custom Dataset class which preprocesses and stores datasets\n",
    "       from CIFAR batch files.  Works for CIFAR-10 and CIFAR-100.\"\"\"\n",
    "    \n",
    "    def __init__(self, X=None, y=None):\n",
    "        self.data = X\n",
    "        self.labels = y\n",
    "        \n",
    "    def load(self, file_list):\n",
    "        # Get list of (X, y) tuples, concatenate corresponding tensors\n",
    "        combined_list = [read_data(file_name) for file_name in file_list]\n",
    "        X_list, y_list = list(zip(*combined_list))\n",
    "        X = torch.cat(X_list, dim=0)\n",
    "        y = torch.cat(y_list, dim=0)\n",
    "        \n",
    "        self.data = normalize(shape_image(X))\n",
    "        self.labels = y\n",
    "        return self\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Generates an (X, y) pair at given index\n",
    "        return self.data[index], self.labels[index]\n",
    "    \n",
    "    def cuda(self):\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            self.data = self.data.to(device)\n",
    "            self.labels = self.labels.to(device)\n",
    "            \n",
    "    def cpu(self):\n",
    "        self.data = self.data.cpu()\n",
    "        self.labels = self.labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = CIFARDataset().load([f\"data/data_batch_{n}\" for n in range(1, 6)])\n",
    "test_set = CIFARDataset().load([\"data/test_batch\"])\n",
    "cifar_meta = unpickle(\"data/batches.meta\")\n",
    "\n",
    "# Visualize a few random examples\n",
    "def plot_image(x, ax):\n",
    "    \"\"\"Helper to scale and plot output from ImageDataset.\"\"\"\n",
    "    image = (x.squeeze().permute(1, 2, 0) + 1) / 2\n",
    "    ax.imshow(image.clone().cpu().detach())\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for i in range(3):\n",
    "    X, y = train_set[i*1000]\n",
    "    plot_image(X, ax[i])\n",
    "    ax[i].set_title(cifar_meta[b'label_names'][y.item()].decode('ascii'))\n",
    "plt.suptitle(\"CIFAR-10 sample images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define architecture for vanilla generator and discriminator\n",
    "# See also: https://gluon.mxnet.io/chapter14_generative-adversarial-networks/dcgan.html\n",
    "# https://github.com/soumith/ganhacks\n",
    "\n",
    "def conv_block(which_model, conv_args=[], conv_kwargs={'bias': False},\n",
    "               leak_slope=0.02, batch_norm=True, activation=True):\n",
    "    \"\"\"Performs all the operations in a single DCGAN layer in the following order:\n",
    "       batch normalization -> convolution (optional) -> nonlinearity (optional)\n",
    "       \n",
    "       If which == 'gen', does a transpose convolution\n",
    "       If which == 'dis', does a normal convolution\n",
    "       Returns a list of functions in order; should unpack and fill in nn.Sequential\"\"\"\n",
    "    \n",
    "    funcs = []\n",
    "    \n",
    "    if which_model == 'gen':\n",
    "        funcs.append(nn.ConvTranspose2d(*conv_args, **conv_kwargs))\n",
    "        if batch_norm:\n",
    "            funcs.append(nn.BatchNorm2d(conv_args[1], affine=False))\n",
    "        if activation:\n",
    "            funcs.append(nn.ReLU())\n",
    "            \n",
    "    elif which_model == 'dis':\n",
    "        funcs.append(nn.Conv2d(*conv_args, **conv_kwargs))\n",
    "        if batch_norm:\n",
    "            funcs.append(nn.BatchNorm2d(conv_args[1], affine=False))\n",
    "        if activation:\n",
    "            funcs.append(nn.LeakyReLU(leak_slope))\n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Argument `which_model` is not a valid value\")\n",
    "        \n",
    "    # Initialize the weights to match DCGAN paper?\n",
    "    # Build a list of the three functions in sequence\n",
    "    return funcs\n",
    "    \n",
    "\n",
    "class DCGenerator(nn.Module):\n",
    "    \"\"\"Deep convolutional generator which maps latent noise vector -> (32,32) RGB-channel image.\n",
    "       The latent space input z is projected and convolved with many feature maps.\n",
    "       Subsequent layers use only fractional-strided convolutions (no pooling).\n",
    "       All hidden layers use ReLU activation, and output layer uses tanh.\"\"\"\n",
    "    \n",
    "    def __init__(self, z_len=128):\n",
    "        \n",
    "        super(DCGenerator, self).__init__()\n",
    "        self.z_len = z_len\n",
    "        \n",
    "        self.in_layer = nn.Linear(z_len, 128 * 4 * 4)\n",
    "        \n",
    "        # Choose kernel_size, stride, padding to double height/width for each layer\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            #*conv_block('gen', [z_len, 128, 4, 1, 0]),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            *conv_block('gen', [128, 128, 4, 2, 1]),\n",
    "            *conv_block('gen', [128, 128, 4, 2, 1]),\n",
    "            *conv_block('gen', [128, 3, 4, 2, 1], batch_norm=False, activation=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        # Reshape z as 4d tensor, with latent code vector along channel dimension\n",
    "        z = self.in_layer(z).view(-1, 128, 4, 4)\n",
    "        return self.conv_layers(z)\n",
    "\n",
    "\n",
    "class DCDiscriminator(nn.Module):\n",
    "    \"\"\"Deep convolutional discriminator which maps (32,32) RGB-channel image -> [0, 1].\n",
    "       The image is passed through several convolutional layers (again, no pooling).\n",
    "       All hidden layers use LeakyReLU activation, and output layer uses sigmoid.\"\"\"\n",
    "    \n",
    "    def __init__(self, leak_slope=0.02):\n",
    "        \n",
    "        super(DCDiscriminator, self).__init__()\n",
    "        \n",
    "        # Just reverse the convolutional layers from the Generator\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            *conv_block('dis', [3, 128, 4, 2, 1], batch_norm=False),\n",
    "            *conv_block('dis', [128, 128, 4, 2, 1]),\n",
    "            *conv_block('dis', [128, 128, 4, 2, 1])\n",
    "        )\n",
    "        \n",
    "        self.out_layer = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        # Reshape discriminator output by flattening, then feed into sigmoid activation\n",
    "        x = x.view(-1, torch.prod(torch.tensor(x.shape[1:])))\n",
    "        return self.out_layer(x)\n",
    "        #return torch.sigmoid(self.out_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = DCGenerator()\n",
    "dis = DCDiscriminator()\n",
    "z_test = torch.rand(5, 128)\n",
    "dis(gen(z_test)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN Training\n",
    "\n",
    "The training is done using the minimax game described in the original GAN paper by <a href=\"https://arxiv.org/pdf/1406.2661.pdf\">Goodfellow, et al (2014)</a>.  The choice of optimizer and batch size are specific to the DCGAN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to train built models and evaluate convergence\n",
    "\n",
    "def jensen_shannon(which_model, device):\n",
    "    \"\"\"Returns a function to compute an empirical estimate of the Jensen-Shannon\n",
    "       divergence between the true data-generating distribution P_real and\n",
    "       the generated distribution P_model over parallel batches x_real and x_model.\n",
    "       \n",
    "       This metric is optimized by a minimax operation, first maximizing over the\n",
    "       discriminator weights, then minimizing over the generator weights.\n",
    "       \n",
    "       Returns:\n",
    "       - if which_model = 'dis': returns function (D(x_model), D(x_real)) -> scalar\n",
    "       - if which_model = 'gen': returns function (D(x_model)) -> scalar\n",
    "         Both functions are returned in the form of minimization problems.\n",
    "       - if which_model = 'full': returns non-negative version of 'dis' function.\n",
    "         Use this version to calculate divergence after an epoch.\"\"\"\n",
    "    \n",
    "    if which_model == 'dis':\n",
    "        #return lambda dis_model, dis_real: \\\n",
    "            #-torch.mean(torch.log(dis_real) + torch.log(1 - dis_model))\n",
    "        bce = nn.BCELoss()\n",
    "        model_loss = lambda d_model: \\\n",
    "            bce(d_model, torch.zeros(d_model.size()).to(device))\n",
    "        real_loss = lambda d_real: \\\n",
    "            bce(d_real, torch.ones(d_real.size()).to(device))\n",
    "        return lambda d_model, d_real: \\\n",
    "            model_loss(d_model) + real_loss(d_real)\n",
    "        \n",
    "    elif which_model == 'gen':\n",
    "        # If generated samples are rejected easily, log(1 - D(x_model)) saturates\n",
    "        # (stays close to 0), so use an approximation to improve early training\n",
    "        #return lambda dis_model: \\\n",
    "            #-torch.mean(torch.log(dis_model))\n",
    "        bce = nn.BCELoss()\n",
    "        return lambda d_model: \\\n",
    "            bce(d_model, torch.ones(d_model.size()).to(device))\n",
    "    \n",
    "    elif which_model == 'full':\n",
    "        return lambda dis_model, dis_real: \\\n",
    "            torch.mean(torch.log(dis_real) + torch.log(1 - dis_model))\n",
    "   \n",
    "    else:\n",
    "        raise ValueError(\"Argument `which_model` is not a valid value\")\n",
    "\n",
    "        \n",
    "def train_DCGAN(gen, dis, train_set, test_set,\n",
    "                num_epochs=100, dg_ratio=1, batch_size=128,\n",
    "                use_cuda=True):\n",
    "    \"\"\"Simultaneously trains generator and discriminator using minimax optimization of\n",
    "       Jensen-Shannon divergence between discriminator performance on x_real vs. x_model.\n",
    "       Uses ADAM optimizer for both networks, using params defined in DCGAN paper.\n",
    "       Latent codes Z are drawn from a uniform prior.\n",
    "       \n",
    "       Parameters\n",
    "       - num_epochs: the number of training epochs over the dataset\n",
    "       - dg_ratio: the ratio of discriminator batches to generator batches\n",
    "       - batch_size: the train_set batch size passed into discriminator\n",
    "                     (for each real batch, an equal-sized batch is generated by generator)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move to GPU if possible; batches get moved as needed to save on memory\n",
    "    device = \"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    criterion_dis = jensen_shannon(\"dis\", device)\n",
    "    criterion_gen = jensen_shannon(\"gen\", device)\n",
    "    optimizer_dis = torch.optim.Adam(dis.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "    # Keep a global count of how many discriminator steps happen per generator step\n",
    "    # because dg_ratio may not divide evenly into batch_size\n",
    "    dis_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        #print(f\"EPOCH {epoch+1}\")\n",
    "        \n",
    "        for X, y in loader:\n",
    "            z = torch.rand((X.shape[0], gen.z_len)).to(device)\n",
    "            X = X.clone().to(device, non_blocking=True)\n",
    "            \n",
    "            # Discriminator trains each batch\n",
    "            optimizer_dis.zero_grad()\n",
    "            loss_dis = criterion_dis(dis(gen(z)), dis(X))\n",
    "            loss_dis.backward()\n",
    "            optimizer_dis.step()\n",
    "            dis_count += 1\n",
    "            \n",
    "            # Generator trains if enough discriminator passes have gone through\n",
    "            if dis_count >= dg_ratio:\n",
    "                z = torch.rand((batch_size, gen.z_len)).to(device)\n",
    "                optimizer_gen.zero_grad()\n",
    "                loss_gen = criterion_gen(dis(gen(z)))\n",
    "                loss_gen.backward()\n",
    "                optimizer_gen.step()\n",
    "                dis_count = 0\n",
    " \n",
    "        # Evaluate how the model is performing on test set after a full epoch\n",
    "        print(f\"- EPOCH {epoch+1}:\" +\n",
    "              f\"\\n  discriminator loss = {loss_dis}\" +\n",
    "              f\"\\n      generator loss = {loss_gen}\" +\n",
    "              \"\\n----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Possible function if we need more abstraction in sampling from the noise\n",
    "# (if it gets more complex than uniform vs. normal)\n",
    "def generate_noise(curr_batch_size, latent_dim, distribution, device):\n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_wasserstein_loss(which_model, d_real, d_model, device):\n",
    "    \"\"\"Returns a function to compute an empirical estimate of the Wasserstein\n",
    "       loss between the true data-generating distribution P_real and\n",
    "       the generated distribution P_model over parallel batches x_real and x_model.\n",
    "       \n",
    "       This metric is optimized by a minimax operation, first maximizing over the\n",
    "       discriminator weights, then minimizing over the generator weights.\n",
    "       \n",
    "       Returns:\n",
    "       - if which_model = 'dis': returns function (D(x_model), D(x_real)) -> scalar\n",
    "       - if which_model = 'gen': returns function (D(x_model)) -> scalar\n",
    "         Both functions are returned in the form of minimization problems.\n",
    "       - if which_model = 'full': returns non-negative version of 'dis' function.\n",
    "         Use this version to calculate divergence after an epoch.\"\"\"\n",
    "    \n",
    "    if which_model == 'dis':\n",
    "        return torch.mean(d_real - d_model).to(device)\n",
    "    elif which_model == 'gen':\n",
    "        return - torch.mean(d_model).to(device)\n",
    "    else: \n",
    "        raise ValueError(\"Argument `which_model` is not a valid value\")\n",
    "\n",
    "# NOTES:\n",
    "# - WGAN uses RMSProp\n",
    "def train_WGAN(gen, dis, train_set, test_set,\n",
    "               num_epochs=100, dg_ratio=5, batch_size=64,\n",
    "               use_cuda=True):\n",
    "    \"\"\"Simultaneously trains generator and discriminator using minimax optimizatinon of\n",
    "       an estimate of the Earth-Mover/Wasserstein loss induced by weight clipping\n",
    "       between the the true distribution and the model's distribution.\n",
    "       \n",
    "       Parameters\n",
    "       - num_epochs: the number of training epochs over the dataset\n",
    "       - dg_ratio: the ratio of discriminator batches to generator batches\n",
    "       - batch_size: the train_set batch size passed into discriminator\n",
    "                     (for each real batch, an equal-sized batch is generated by generator)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move to GPU if possible; batches get moved as needed to save on memory\n",
    "    device = \"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    criterion_dis = wasserstein(\"dis\", device)\n",
    "    criterion_gen = wasserstein(\"gen\", device)\n",
    "    optimizer_dis = torch.optim.Adam(dis.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "    \n",
    "    # Keep a global count of how many discriminator steps happen per generator step\n",
    "    # because dg_ratio may not divide evenly into batch_size\n",
    "    for epoch in range(num_epochs):\n",
    "        #print(f\"EPOCH {epoch+1}\")\n",
    "        \n",
    "        for i, (X, y) in enumerate(loader):\n",
    "            z = torch.rand((X.shape[0], gen.z_len)).to(device)\n",
    "            X = X.clone().to(device, non_blocking=True)\n",
    "            \n",
    "            # Discriminator trains each batch\n",
    "            optimizer_dis.zero_grad()\n",
    "            loss_dis = criterion_dis(dis(gen(z)), dis(X))\n",
    "            loss_dis.backward()\n",
    "            optimizer_dis.step()\n",
    "            \n",
    "            # Generator trains if enough discriminator passes have gone through\n",
    "            if i % dg_ratio == 0:\n",
    "                z = torch.rand((batch_size, gen.z_len)).to(device)\n",
    "                optimizer_gen.zero_grad()\n",
    "                loss_gen = criterion_gen(dis(gen(z)))\n",
    "                loss_gen.backward()\n",
    "                optimizer_gen.step()\n",
    "                dis_count = 0\n",
    " \n",
    "        # Evaluate how the model is performing on test set after a full epoch\n",
    "        print(f\"- EPOCH {epoch+1}:\" +\n",
    "              f\"\\n  discriminator loss = {loss_dis}\" +\n",
    "              f\"\\n      generator loss = {loss_gen}\" +\n",
    "              \"\\n----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DCGenerator().cuda()\n",
    "dis = DCDiscriminator().cuda()\n",
    "train_set = CIFARDataset().load([f\"data/data_batch_{n}\" for n in range(1, 2)])\n",
    "test_set = CIFARDataset().load([\"data/test_batch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- EPOCH 1:\n",
      "  discriminator loss = 0.48668432235717773\n",
      "      generator loss = 8.547712326049805\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "gen = DCGenerator()\n",
    "dis = DCDiscriminator()\n",
    "train_DCGAN(gen, dis, train_set, test_set, dg_ratio=1, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- EPOCH 1:\n",
      "  discriminator loss = 0.5145567655563354\n",
      "      generator loss = 4.9787797927856445\n",
      "----------------------------------\n",
      "- EPOCH 2:\n",
      "  discriminator loss = 0.03312017768621445\n",
      "      generator loss = 4.456597328186035\n",
      "----------------------------------\n",
      "- EPOCH 3:\n",
      "  discriminator loss = 0.134837806224823\n",
      "      generator loss = 6.0797119140625\n",
      "----------------------------------\n",
      "- EPOCH 4:\n",
      "  discriminator loss = 0.7221261262893677\n",
      "      generator loss = 5.328575611114502\n",
      "----------------------------------\n",
      "- EPOCH 5:\n",
      "  discriminator loss = 0.5090416073799133\n",
      "      generator loss = 5.536656379699707\n",
      "----------------------------------\n",
      "- EPOCH 6:\n",
      "  discriminator loss = 0.8616710305213928\n",
      "      generator loss = 3.7526612281799316\n",
      "----------------------------------\n",
      "- EPOCH 7:\n",
      "  discriminator loss = 0.7959845066070557\n",
      "      generator loss = 2.055325984954834\n",
      "----------------------------------\n",
      "- EPOCH 8:\n",
      "  discriminator loss = 0.9165799021720886\n",
      "      generator loss = 3.237531900405884\n",
      "----------------------------------\n",
      "- EPOCH 9:\n",
      "  discriminator loss = 1.2645212411880493\n",
      "      generator loss = 2.064612627029419\n",
      "----------------------------------\n",
      "- EPOCH 10:\n",
      "  discriminator loss = 0.48343050479888916\n",
      "      generator loss = 2.94064998626709\n",
      "----------------------------------\n",
      "- EPOCH 11:\n",
      "  discriminator loss = 0.17515829205513\n",
      "      generator loss = 2.990819215774536\n",
      "----------------------------------\n",
      "- EPOCH 12:\n",
      "  discriminator loss = 0.5459546446800232\n",
      "      generator loss = 2.08565092086792\n",
      "----------------------------------\n",
      "- EPOCH 13:\n",
      "  discriminator loss = 0.6429862380027771\n",
      "      generator loss = 3.4230360984802246\n",
      "----------------------------------\n",
      "- EPOCH 14:\n",
      "  discriminator loss = 1.2377204895019531\n",
      "      generator loss = 2.3895249366760254\n",
      "----------------------------------\n",
      "- EPOCH 15:\n",
      "  discriminator loss = 1.9789764881134033\n",
      "      generator loss = 2.0616185665130615\n",
      "----------------------------------\n",
      "- EPOCH 16:\n",
      "  discriminator loss = 0.23470568656921387\n",
      "      generator loss = 2.3204269409179688\n",
      "----------------------------------\n",
      "- EPOCH 17:\n",
      "  discriminator loss = 2.1134164333343506\n",
      "      generator loss = 4.1800217628479\n",
      "----------------------------------\n",
      "- EPOCH 18:\n",
      "  discriminator loss = 1.2522283792495728\n",
      "      generator loss = 3.759880542755127\n",
      "----------------------------------\n",
      "- EPOCH 19:\n",
      "  discriminator loss = 0.2890414297580719\n",
      "      generator loss = 3.042475938796997\n",
      "----------------------------------\n",
      "- EPOCH 20:\n",
      "  discriminator loss = 0.1732354760169983\n",
      "      generator loss = 3.3680381774902344\n",
      "----------------------------------\n",
      "- EPOCH 21:\n",
      "  discriminator loss = 0.8079128265380859\n",
      "      generator loss = 2.2342865467071533\n",
      "----------------------------------\n",
      "- EPOCH 22:\n",
      "  discriminator loss = 0.2542175352573395\n",
      "      generator loss = 3.8591084480285645\n",
      "----------------------------------\n",
      "- EPOCH 23:\n",
      "  discriminator loss = 0.5722243785858154\n",
      "      generator loss = 2.2468299865722656\n",
      "----------------------------------\n",
      "- EPOCH 24:\n",
      "  discriminator loss = 0.5467395782470703\n",
      "      generator loss = 0.8462978601455688\n",
      "----------------------------------\n",
      "- EPOCH 25:\n",
      "  discriminator loss = 0.8342372179031372\n",
      "      generator loss = 2.0876848697662354\n",
      "----------------------------------\n",
      "- EPOCH 26:\n",
      "  discriminator loss = 0.34974247217178345\n",
      "      generator loss = 2.744049072265625\n",
      "----------------------------------\n",
      "- EPOCH 27:\n",
      "  discriminator loss = 0.24689245223999023\n",
      "      generator loss = 3.252251148223877\n",
      "----------------------------------\n",
      "- EPOCH 28:\n",
      "  discriminator loss = 0.6633423566818237\n",
      "      generator loss = 2.924353837966919\n",
      "----------------------------------\n",
      "- EPOCH 29:\n",
      "  discriminator loss = 2.120924711227417\n",
      "      generator loss = 1.3743305206298828\n",
      "----------------------------------\n",
      "- EPOCH 30:\n",
      "  discriminator loss = 0.34438538551330566\n",
      "      generator loss = 2.630150318145752\n",
      "----------------------------------\n",
      "- EPOCH 31:\n",
      "  discriminator loss = 2.1438939571380615\n",
      "      generator loss = 4.555350303649902\n",
      "----------------------------------\n",
      "- EPOCH 32:\n",
      "  discriminator loss = 0.5042521953582764\n",
      "      generator loss = 1.8485229015350342\n",
      "----------------------------------\n",
      "- EPOCH 33:\n",
      "  discriminator loss = 0.3505783677101135\n",
      "      generator loss = 2.2635650634765625\n",
      "----------------------------------\n",
      "- EPOCH 34:\n",
      "  discriminator loss = 0.4054511487483978\n",
      "      generator loss = 3.781423807144165\n",
      "----------------------------------\n",
      "- EPOCH 35:\n",
      "  discriminator loss = 0.136846125125885\n",
      "      generator loss = 4.249208927154541\n",
      "----------------------------------\n",
      "- EPOCH 36:\n",
      "  discriminator loss = 0.7805456519126892\n",
      "      generator loss = 4.041322708129883\n",
      "----------------------------------\n",
      "- EPOCH 37:\n",
      "  discriminator loss = 0.5340608358383179\n",
      "      generator loss = 2.5617618560791016\n",
      "----------------------------------\n",
      "- EPOCH 38:\n",
      "  discriminator loss = 0.5842595100402832\n",
      "      generator loss = 2.902991771697998\n",
      "----------------------------------\n",
      "- EPOCH 39:\n",
      "  discriminator loss = 0.7900312542915344\n",
      "      generator loss = 1.9747878313064575\n",
      "----------------------------------\n",
      "- EPOCH 40:\n",
      "  discriminator loss = 0.6286906599998474\n",
      "      generator loss = 2.192101001739502\n",
      "----------------------------------\n",
      "- EPOCH 41:\n",
      "  discriminator loss = 0.17659945785999298\n",
      "      generator loss = 3.848334789276123\n",
      "----------------------------------\n",
      "- EPOCH 42:\n",
      "  discriminator loss = 0.13376519083976746\n",
      "      generator loss = 2.4177310466766357\n",
      "----------------------------------\n",
      "- EPOCH 43:\n",
      "  discriminator loss = 0.2372065633535385\n",
      "      generator loss = 3.02192759513855\n",
      "----------------------------------\n",
      "- EPOCH 44:\n",
      "  discriminator loss = 0.23655131459236145\n",
      "      generator loss = 2.7891757488250732\n",
      "----------------------------------\n",
      "- EPOCH 45:\n",
      "  discriminator loss = 0.20370689034461975\n",
      "      generator loss = 3.4558887481689453\n",
      "----------------------------------\n",
      "- EPOCH 46:\n",
      "  discriminator loss = 0.4449780583381653\n",
      "      generator loss = 6.422938346862793\n",
      "----------------------------------\n",
      "- EPOCH 47:\n",
      "  discriminator loss = 0.904104471206665\n",
      "      generator loss = 3.1461410522460938\n",
      "----------------------------------\n",
      "- EPOCH 48:\n",
      "  discriminator loss = 0.18769754469394684\n",
      "      generator loss = 4.758466720581055\n",
      "----------------------------------\n",
      "- EPOCH 49:\n",
      "  discriminator loss = 0.4423893988132477\n",
      "      generator loss = 3.490917205810547\n",
      "----------------------------------\n",
      "- EPOCH 50:\n",
      "  discriminator loss = 0.38701239228248596\n",
      "      generator loss = 3.624755620956421\n",
      "----------------------------------\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%time train_DCGAN(gen, dis, train_set, test_set, dg_ratio=1, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images discriminator:\n",
      "tensor([[0.0004],\n",
      "        [0.0003],\n",
      "        [0.0004],\n",
      "        [0.0004],\n",
      "        [0.0004],\n",
      "        [0.0004],\n",
      "        [0.0004],\n",
      "        [0.0004],\n",
      "        [0.0004],\n",
      "        [0.0004]], grad_fn=<SigmoidBackward>)\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fdb41648af80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fake images discriminator:\\n{dis(gen(z_test[:10]))}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Real images discriminator:\\n{dis(train_set[:10][0].cuda())}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Possible labels: {[label.decode('ascii') for label in cifar_meta[b'label_names']]}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m             raise RuntimeError(\n\u001b[1;32m    185\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAADZCAYAAACttwAaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAokUlEQVR4nO3deZRdZZku8HfvM9dw6tSYqkolqcyEJJAQppAgCCoo0iqIgC2ttBcaVsNFvbbY3V5tu20HnO3W5dDqVRRBvYLKKMjQzAoEQgiZK0MlVZWqVJ2aznz2vn/w7/Ps+8XFul2u+/z+fHftb5+9zz77q7PW873HC8PQREREJJr/X/0CRERE/hxowhQREXGgCVNERMSBJkwREREHmjBFREQcaMIUERFxEI/a+PK2r8I1J3dteD/d54rpIqyf2XwHrB8o7aFjdc+/EdaHBhthfVH693Ssw9NfgPWvNL4I6x+sHKFjrWr5DKwfmNoB651nX0zHGnj0dFhf3f9NWH/17ofoWI+eugXWR4uH6D4393wc1odHR2C97dIYHeupX34a1s/f/DFYf/GSITrWfTdvg/VNpQdg/e0n4/vLzOyxVwqwvv7D/wjruz6/kL+uy++E9b/+9S0e3WmO+N5vHoKf58Edz9N9RgdehfV6HT865i08gY61cOkqWG/txtc7neGPp12vPAXrB/ZshfXq9AwdK0bOJdvaAuvxdAMd6/RNb4D1ZSvwdSlNjtOxXtmGP89BUKH7VKolWN/+ysuwPpUfo2OVK2VYr1bwM2D8GP6cmZlNz+J5oVbHx+jqaqdjtbY1wXo9nMbHqNKhrFTEyyrv+tUD8POsb5giIiIONGGKiIg40IQpIiLiQBOmiIiIA02YIiIiDiJTsps++hFYny7hupnZDcOTsD4wdA2sN/tZ/gKCG2B5+TsWwfqxwWN0KD/91+QYGVi++SyeXhu861RYb/J/SI7xBB1rQQwnzmo/rsG6vz7iLQuWwfLtsTPoLgfa/gjrLX5AjkHqZnaGj///Cr6H9/Gvifh/LVgNyw/4OKW65QN76VDzfJIErL0Hlhcl+Ou6/d6H6ba5bmoC39PtuTa6T9g5D9fj+HPbs3AJHase4LiiH+B0ZVDAnwEzs9IE/qyHRZwSnd/RRcdauAB/bhYsw8+Z3vl9dKyuLny9EokUrNdyPHG7oK8b71PjKdlSCadR8xM4JTw2xp9z8WQab/DwM6u1HZ+jmVm6EY81OYWPn0rz51wQ4vsiEcfHn5qcoGNVysf34yP6hikiIuJAE6aIiIgDTZgiIiIONGGKiIg40IQpIiLiQBOmiIiIg8hlJZO34npE6t7aAtyw2Dwcha5HHD+o4+UbiV+zPXjD3uqLuM7OJRHwqL15+FXX7G9hvR7iZvFmZil6AfBb0/th/rKOkHO5IniW7+ThGHrJw8ttJg7y5us9dMUJeWHX8ZfFdrkgeBfe4OEmzmZmM/+LxN39jbDcFHFTHrjkLrzhwjfyneaKKl7WUSnz7tSFAv7c9q+YD+szs7N0LNYYvK2DNDmPeNAsX74C1s86Ez8z5s/jS0FaWjphvRrHN0JDmi+fiJNVCl4NL4UozvKm8GXyfjVk+FKU1hxePrN0yYmw/uqrO+lY5uHjl8t4GVBLtpUOlUji+uQUvr9C40tnggBf5IkJfO8VC/zZEB7fqhJ9wxQREXGhCVNERMSBJkwREREHmjBFREQcaMIUERFxEJmS9bt34w3BcrrPQjIFH/TwoXjm0swexQlOezMu+wneGNyqL+B6Dafqov+VmIJVejFjOB0YxTd2LhFXrJVEviLPZQOskrbLZv3HGSuzqHOJeGHsNOkul9OhmtgGn6SH6cmbPVi5GtYjwstzRo005vZqPBacSuK09OQYbmjf3s3TqAtX4ybnXQt6YT3BopVmZjWc4KzW8GdtxxD/YYbCvlE8lo+TmjtffomOddoqnEZ9w+mnwXoYEdOcmsI/ZHHwwBG6TzKBb95kEjfL7+jEaWczs4OH8PM/mcYp3ZkiT0hPTeH7JZ7wYD2b5UngYhGndOukV3+txueFVCriHgP0DVNERMSBJkwREREHmjBFREQcaMIUERFxoAlTRETEQWRKduDgSlhfFBVtTR3G9SKem9s+x4caJ2lY80ifV95+0Pw4TsMG9Ar088FC3DPRx4Evq/fwoYIhnGrzA5z2i/k8VXfvBK7j7pKvWRduh/U4OZdnI977O+r4Yn4xxKm+GDmGmdmTJLj5JPn7j4Z30bHY+/K9i3H9zntwatLM7H9/6yjdNteVCzjF2JThseBsG+6zesrJ62B9wRKeoJ8m/VR37jsE61MFnIY0M5vJ52H9WB6nYYeGyYfDzLKkl6z5uAfpb2//JR0rcfl7YP2cjZvx3yd4H9/ubpwethAnTs3M8hPTsP7Clq2wHk/wvriNzThZW6vjZ1BlJk/HipGvZp2duP93vc4f5sfG8efTN5ysjcf5NJfL5eg2fAwRERH5v9KEKSIi4kATpoiIiANNmCIiIg40YYqIiDjQhCkiIuIgclnJ8j7ctLYtosf5hL8I1qsfwhFt+waPNS8lvXwHGsdhPQh5DN3YMgVyLmf7ZHmMmVmKNavGay7iuL+5mZmFd+PlI4Fdx3ciPkjOZSjq3yLvfrLhQlg9g/fpNjO8bOBL4SlRO0E3kXN5zsfX+GZvKGI0vLDm+qfwXwcBWWZgZt+pXQHrN9nPIo4/N6RSCVivxprpPsUMbl0/MIUbub/4xB/oWOPHZmD98JERWE9ErDtK+PgGKdfwcoRSiS9T6OnEj8GjwwdgPZviz6zpPP5hhl0DA/jYPR10rEQCv66eBd10n16y7eAwXrqz82VcNzPr6sGfg/0HybKWKp8YggreVo/jB0o6ya9xKo7v42IJj5XNttCx4nF+HETfMEVERBxowhQREXGgCVNERMSBJkwREREHmjBFREQcRKZkCzgkZsmoafZrOClpN+FkU3BjxFgZnKzy6+QFeD+nQ/n48HY2O5dzeVNkewSn94LF5O9/w9NjfpWdyyZcth/TsWgaNqLJuQUHcZntE0Scyxg7lzVkj4fpWM+xc/FxEi6s84bp7Fzqozg5mXg6SceayryBbpvrGhrmwfrRPPnMmtmeQzhFuf2VbbDuk2SnmVm9jD9TxWkch4+RJKyZWbGM06gT07g+PYMTumZmA4OvwnpTBqeHT1iGf5TCzMxISvfJxx+F9UWL2UPDbMXKFbDe3s5Tn6k0vv4tWZwG9WuTdKzZMv4QFgt4xUMxjxu/m5nV6zhVnc7gB/PMFB8r24zPP5XGCfpKhT/LCxEN/hF9wxQREXGgCVNERMSBJkwREREHmjBFREQcaMIUERFxEJmSTS0i/TmDHr4TmYKDD+ENPum/amZmHhksZIf+AB/LrsXlgCQEI/6VqJHXRXfxj///Et/eSbb8Dd+JhQojDl/28HV5fc/lVrJlPt/pOM/l197qiOOzDSQNG5Eq/pH/JKz/z9r1fKc5IteG+5buObSL7nNkP+6B2pjAScn87AQda2YS94z1SPI6P82Trfki7sEcJ/1yO+bhhLCZWYakLuf3nwzrC0ga08xs4KWnYT3m4fRstc6bM4+OHYP1tWtX0X2WLV8C6wtIX9imM9fTsbbuwAn6cimN64mIXrKWxfUQP3+Hh3kv7yTp5dvSyt5j0pTczIpFpWRFRERed5owRUREHGjCFBERcaAJU0RExIEmTBEREQeaMEVERBxELiv5yARePvLFiGmWDcj7KPNYNZMgx6+GES+MLBUIyC5R/0nEybngsLVZiSyDMTOjq2oCEpGOeGGnk21/iDh8ipzLTvL3K3Fq/jW4X7xZSJaPRCzfyJFzyZO/fwdPtNtj5Pqf8zlcj32KLxv41mfv5wea4/buxXfCjr176D5HjuyF9TpZ8tHc0kTHOmEFbjS+ZhVuzj80iht2m5kdGMVLBTq78edm0VLe5Ly5vQvWRybwMcIxvNTGzOzAfvyLFaN5vERk1Yl0KHvzCrx8ZHaGX5eAPE7DCl7W8soz/AO9fOU6WJ83Pwfrz/zhP+lYwyO4KX61ipeVlAr49ZqZjY/jxuyZplZYD0L+cJgp8CUniL5hioiIONCEKSIi4kATpoiIiANNmCIiIg40YYqIiDiITMl+GYeO7MsRicS0fwTWZ/ze438BpClzlczzgcdfmE/2oeldHzcrNjOr+KOwTlp5mwU4IfYa3JS4FvsJrMftfXSkP9Bz4XHUcR9HSNvYDgHdYmbjeJc4Tpb6diEdKX+c5zJGzsPMDLccN7NB/B7XPzFGx5p84DS84WN0lznjmf98ENbj81bSfZaduBbWMxX8Bq06cTkda+WKPlivl3AqOfR5GnTW8HsUT+CseiyWo2NVa7iZ9+w0vp9bKuQHG8ysVsf34YERPFa6iTcZb8niB/CSpf10n5A854p53GR8x7Nb+FhF/B6vuQB/bteehBu/m5kVn8PPwL17cOK4oZGnrVta2ScaR4SnpvC1NzMrl9R8XURE5HWnCVNERMSBJkwREREHmjBFREQcaMIUERFxEBlSrZM2g7GIabZUJmnYJO4NWPdottRi0+RANAwb8cLYJlYPcBLWzCzp7cC7eCfgQzS38NdFzmWWpWGj/sVhfXEneYK0LXsVflnerXgsnyfO2LlUWBr2TzgXr4bPpcM/iw5V85+C9cZTrsM7BP9Cx/rxdThVeBndY+4YOYjv6VNOvojuk0rhJHEbabfb04tT32Zm43ncA/TQHnxPVQKcXjUz8z2ciIyRRs/1sEzHshp+DNbLOKUb1nkavzmHr9exadyz1E820rGCkH1uI5pTk5fWlMbvS3/vQjpUOoaP4xvuI7x2De/Xm8vlYP03RTwvDA/x58z8LjzH1L0SrCcS+O/NzKamJuk2RN8wRUREHGjCFBERcaAJU0RExIEmTBEREQeaMEVERBxowhQREXEQuawktvFyvOErd/CdaBL8VHyMqBcQsRoD8fl6Ezvu/w0i/5wsH2F/PhsRAyfXq6X6QbLD9/lYRBB5HcnykeM+Ct8pbbeQHY6/Y3lI71i8dMQs4iY/+hlcv5Ef//nvkcbP3+H7zBUNTe2wnoi4PfP5o7CeasvBeqHGP4MlnPq3TGszPkbAfzTASnhZCbs/SlXeZDudwTv5Hl7yEPj8sdnUjpcwJEO8TCKWIb9wYWZhEj8dA4+fi1fHy1T8GH7NiUa+rC/ThLfVynh50LHDI3Ss9ka83OYdb7sA1p97aT8da4YsRSmV8bKpcpE38c818+uP6BumiIiIA02YIiIiDjRhioiIONCEKSIi4kATpoiIiIPIlOyFX8Np2HUf5fu833CyLRduhfXeiCDcUwlcP7uKk2ClEDcFNjOLk+OQQxjO4L3mZyRV+LfkGNUMH2uyuAvWi8F7YT0T8S8Ou5QRIUj7Atn4CBnsgYj3Kwx/C+ul4EpYT7+O/67dEBGQHiDH+V0zPvnaN8foWL+/gjSS/zPQuwg3x/Z8/kaUSlOwPjKFHx3JHEkRm1m1hlOXXgJ/Cosz/PNcDfFrjsdx7LwW443cG7K4MXlXex7Ww3GeuqxUa7DuBfj1ZjL84eCTJQRBiI9hZlav4yeXn8CDhRG/pDEzi9OwXoA/bKmI+2hqFCdoMw1tsP6GjSfRsXbuPQDr27YPw/rMFG58b2aWTKTpNkTfMEVERBxowhQREXGgCVNERMSBJkwREREHmjBFREQcRKZkH/swjkT+rs5zl5/3cePSrIeTh2HES9hYZVtw6skPcL/CSCRdGfg4iWtmdp6H+x+O2a/wDjxUZ2YrYLX+QtQ+mF/G9XqK/1/0Pg9fgJvZDlGRW7sYVj36PnJxsk+NpNqu9PlBNrHMMwnP+R6/jz6Zw/f3L+gec0fo4aRklSQ7zcwK0zgpmSLpzukp3DPVzKxSwjdoYQofIxGRyG5uxKnXzlacusy28c9zZw6fSz2O3+tiil+v8UW4l2y5PoR3iOhxW6+RXrYRPXbrPv48eyQlm2vjvVSDOn5tdXK/tLTwxG/Sww+O/HQe1sMqT0ivW9UN67lmfE/cfffv6Fijw7j/LKNvmCIiIg40YYqIiDjQhCkiIuJAE6aIiIgDTZgiIiIONGGKiIg4iFxW8urncRS4P2qa7c7D8tQQbrwckZA2q+FYs7+3Af+9zxssm+FIe5U0OG7J8Ia9nbN4+Qjpr2zladx43swsk8dNhjPzF8J6qx2kY01m8HW5yOfR9fkkIc/Opb73CTpWYv9mXCfNtVPGl4JUWvCteV2sBOubqvxGqpFzeWbPUVi/+KtddKxlh5fTbXMeWaYQD3DdzKyF9KZe0IKv9wlLcnSspjRedhDz8Bs0O5WnY5UKk7CeacT31MrleLmJmdmCRX2w7icWwfpMnr+uBT09+PgD+F7LtvHm322tuCl8PI6fpWZmAVn2FZLnXLqRPEvNrFbCDwefHCMR1cSfPH/bO5pgfabAn1mzedxkfX4nXg72zovfQse6656H6DZE3zBFREQcaMIUERFxoAlTRETEgSZMERERB5owRUREHESmZFd+/L/jDaVv8J1I6CtGmnxHztgJkuAiKS3foiK3BEmJTpJUmZkZCfXxc+nCSVgzo43Z4x5Og+Lc3GuCIzhZdu9Svs/7jvdc1uEkrJnxZuZhB6wnjDSkNrNwEDdM/247/vveiBsJZ3TNwhPnwXrjGn4f3bkPN/H+HD/8nHHOxg2wvuTEk+k+Rw4fhvX5vTh1umI5v9m6O3H6OBbi6z1NGnObmZVJ03LPx2M1NfLm601N+KEVS+JUbyIiVVycxc28T1mDE7f9K/rpWNUAJ37DiKdmLcAPtDCGr0sswaeAagk/aAPSfN2P89flpclniuxTrvIEfTyGP9H1Sh7WO0kS18xs89mn0W2IvmGKiIg40IQpIiLiQBOmiIiIA02YIiIiDjRhioiIOIhMyS5e/x+w/ine/tD+kszB9QCnZBe38rEGZsiGOsk9Bri/pJnRfw08cgVIEPe1bfhUrPYSrse/wsfyb8MJ0kwV954s8rCfxebjehDk6D4/DfKwXibnmLqMH997ECckvam9sF6LuPu8DvwOhCSGPRzgVLGZWfk2XM+SXslNQ1fRsS68/kW6ba7bcNIJsL56PU/JFtfg97SxBee1yW1jZmahh5OSPkk9tjV287GOM90dkOePmVmNpD6NJDXLZRJtN7Oly3AP6EwSf3CLs/yZFfrkA8IeWmYWeiTZGuJ6nbwnZmYBaUxbKeLzrwf84eTHyXtP3rHpY7yX7IGBQ7C+afN6WC9Up+lYDSy9S+gbpoiIiANNmCIiIg40YYqIiDjQhCkiIuJAE6aIiIgDTZgiIiIOIpeVDG7DTYav5Klqswyeg6/1caz7u1EvgCXBfRz3rrMYtpnFSJf1kJ1Lmq+dOeLjJQz06BO8k3twK45PH8ri5tZtxXE6VnwKHyfTQrqim9kL5F+mFGtkX4i4ZRqOwPLQTS2wPi9iGVBqCO9jPZ2w/BsfL10x4+eS+hE++dkP3k/HKjyxhm6b6zKkAXlTOkX3aWwg73cc32tkJYKZmXlsWQmpB2z9lpkFVbyNLZ/w/IiG5eRBQ/q4W8h+fcHMmnL4c1ur42PUg4hfeQjwCwgN/zCBmZnPXnQd1+tx9tMEZiFbXFfD84IX8NeVIueZqONr2Vji1yUcwQ/t0X0jsN63so+ONeaztYuYvmGKiIg40IQpIiLiQBOmiIiIA02YIiIiDjRhioiIOIhMyW67CCcV+zPH6D6xHE6jfnccp06XkcSpmdkelvgaxemtH7eTJspmvPk6CcPGDvLXNb+vAdbHkzjx2tnGE1+xKt7nG6SZeKIBH9vMLJHD6bHO3/O04epzcfP3ShN+j1NNuOm2mVkswPt8Jyzjv/8mP5eWPpxeS5dwI+WLkvPoWLONY7C+9MaHYP3sXefSseK34nP5c9DcghOcIWl+bmZWKONEZFjG16FM/t7MbHYGp7UrVbxPuYzT8GZmtRq+p6ukYXqVHMPMrFDAn8HCLL7XahGN3Jvb8DOzuSUH67lm/PkzM0snk7BeD/i5mIefgT5ZJdDczFcDHDuKj1Mq4s9mEPBf0vAMn0tQx/dRtpkntxctxJ/1YgHfX2HA54WW5ohfswD0DVNERMSBJkwREREHmjBFREQcaMIUERFxoAlTRETEgSZMERERB15ImhWbmTU2x+HGwgxvsvtfiyxDMTNjjYRfx6P8SUfIkXp+KSzHjTcZryXw/z9x0qjazKyBnM00qYe0I76ZsR7Hg+8kx76LDlX0cAw9HsPLBmIRK4pqpLl33cPLKeJ38HPsv3ohrO+a3hN1880JX/rC1+EtWk800X0mJnBD65lJvFTHj/gQsCUnIyP4GPWITu5tnV2w3trRDuupGF9BNzueh/Vdu1+F9clpvNzEzGzhkn5YjyXwvZZtxq/XzGzxYnyv9S3o5vssmQ/rbSl8e46++hgda3JwP96QxNeyezl+T8zMYnH8eU4Yvi4ptt7PzCbH8fWvhnheyrTxJSoVw0vbznzLDfCC6RumiIiIA02YIiIiDjRhioiIONCEKSIi4kATpoiIiIPI5uvnLMbJpvu34SbfZmYW4kRSa4Cb7FYjpmyeRTsHVmMBT3zVX89/DUiI8ofkal7N+yubHf05LN85cw2sX4J7O5uZWSzELyzu4abbZmab63lYf/8qPNbVR/jxqyO7YH3/9NtgfX4LD5Y2pXEatqH0Rlj/Ze1FOtZLi/Kwfl8Jn+ORq7bRsT571dV021z34CNPwXqubyXdJ6zjRtsvPPkwrPcvWEDH6mjHidDBQ0OwXgt4Gr+hLQfrFR+/pyODh+hY55++EdbXnbQa1gtl/sMMfgI/BAYOHoD1Xbt56n3ry1tgvTXHU82XvvtdsL5p9QpYT4b8wdjXg9/LSgz/mITHfizDzAKyGqNq+D324/y9T+Vwgjbj43MJYrxZPf/ZAUzfMEVERBxowhQREXGgCVNERMSBJkwREREHmjBFREQcRKZkXxnCDTrD70bsdA3ep49MzVujXgBt2orTsDNP8KEypJ6t4oNMJfrpWEf8g7DeQxJfhttumpmZ712JX9d+nCoj7RLNzGzTbnyWj5/A+zL+fcsyWH/DLE68JiI6pvrxtbB+5zMkCRfRlvYtl+C09Z2/+gOs39GMk3tmZt8q42vZlMD3ai1xEh3rS9txv8y30j3mjsuu/CtYT3Utp/sUpodhfdfWl2C9p5unZH2SYsykcfS7EvA0/oo1+DW39uD3p9DRSsd6+1vfBOsNzfjzNBuRkg3I56NGEuylGh/r6NFxWD8wwKPqDQ1ZWB8ePAbr+1/ZTcfyS/i17Rs+Cuunv+VUOtai/l5Yr9bxZ9BP4xUaZmaWwM8TLyANpT3+0Ex6EQ8hQN8wRUREHGjCFBERcaAJU0RExIEmTBEREQeaMEVERBxowhQREXEQuazk6Q04Iz0f9wU3M7NWH0d4t9bw0oZxn8eqC+cPwnrf032wntzcSMda6M3C+qFW3Mj4LxoH6FjzSVf4egxfrz9+9nk61sULT4H1xBK83OPhBv66/vVtN8L6P136dbrPW2/FcfNaYwOsD378H+hYb7/qn2G9rRefy740bkhtZvbg4E2w/okLvwTr1/6AL50ZbMVLVO4+9SFc78PN/c3M1mTX0W1zXSqJ/z/etYM3m5+axMtKQtZMu8IbXc/M4M+g5+HPTTrFW2NXC/hDODmKX9fIQd58/b4H7oP1iWlyjJlJOlZzFi/raGnFP4DQmMX3ppnZ4CBePtLVMZ/uk87iZTWP34PPcXw3Xh5kZlYv4x9A2DM8AuuDs1N0rOWrcPP3lix+zrS08l+ZyDTgz3pLI75fEmm+5KyhgV9/RN8wRUREHGjCFBERcaAJU0RExIEmTBEREQeaMEVERBx4LO1mZraw7zy48dDtj/AR34HL78V9hO02PhJvvs6E3XRTzHDarz6JD9Lcyq9LNcCNgauGU2V1HOo1M7P2Ej7OZH4RrLckeOPlyUdw6HnD1Ty5uGMXTqMlF5dhfWohPkczszd142v56F0dsL5wzQQda08jvi4rl+L/8V79IX69ZmbxHG6wXE/g9FzfD/mNV7wRN/0e3r3teO/W/+e+9e8/hBf1J7+4h+5zaBinS/0qbozeEOfJViNp2FqNNc3mjbGbczgRn0zgBOX6U3Aa3cxs3Tq8begIToPu3buDjnXsGE6dV0r4XA4P8dT7wP5XYf3U9RvoPjfd8D9g/Ue33ALrtUncSN3MbLKMP1NF8iMTBeNp1NDDz6bGOH6eJJJ8rFgKJ1uzJCXb17+YjvWOS6/A9cveD29WfcMUERFxoAlTRETEgSZMERERB5owRUREHGjCFBERcRDZS/amj+Ck4i281aaNhbhn4M+DXbD+ed5K1j6OW5CaP5SDdS/ASVgzs5D8a+CRNGzReG9SC3B6LH8+HqtrNx/Kn3clrK89+AtYH2nh6d2V5+G+uKv7eapu1cExWL/kPPx+/XYvHco21d8O6+e8sB/WHz6TpyBP8vA1/tjYpbAeDDxAx7ppLe79eabh459+7X+jY+28fCfdNtf1zOuB9RWLeYowJNcoHiN1koQ1M/Nj+EMYBvieTqZ5b2gjadjeXtxn9dwLLqBDNTeQfqbpVljfvo33X925ew+sd/fha1xiDyYzi2Xw69q2i6d0t+/Cn9uGxSfC+uHDuMetmVlbKz7/RBKvEmhoytCxxodx3+ixQfxwHB3DCWUzs1Kd9DEO8L13JM+nubPOP75wu75hioiIONCEKSIi4kATpoiIiANNmCIiIg40YYqIiDjQhCkiIuIgsvl638YE3Hj4d6RZspn5uXZYfyTATYkjVqiYVUgcOImb//6i41Q61GVjf4T11NdwRLr+oTfTse7wnoH1S8M8rCf/mV/j4JM41n35kiWwftu+5+hYKzbj5sOjT6+h+5zr4+bHvwn2wXrrhgIdq7ClE9Z7G3thfe8Mj8e3pfB6o2oZN4tfERHP3xKbhfXGdfjcyy/h5s5mZmdtOBnWf//k03O++fr3v3UbvBGrHl8O4KfxPZVK4ebYcbJ0xMzM9/G2IMRLVGIRzbyrFfwMKFbw/Vkr4WbxZmZeCd8H42P4FyN+de8v6Vjb9+NlJSvW4KVdUzN5OtboCF6KEdT4Dw2sX3sGrPcvXYvHCvmSi7SPtzUk8OejXJqmY7384uN4LMPvV36K/FqHmQ1PzMB6tqMf1qtVvnztzI0bYf22n/y7mq+LiIj8qTRhioiIONCEKSIi4kATpoiIiANNmCIiIg4im6/vWI2beWezebpP8uckDfvut8J6zb+PjhVvPh3WE9WnYP3RGE+Qej4OMTZ/BKft2g/fS8e6ogcnWydIqG/pp2+mY1320udgvbAcv64zmnhD6vVbVsN69Yu8WfSWa3BOeWfrAKx/ZPs/0rFOve5f8YYP48Tv0ZW4ubSZ2an+tbD+yuJvwvrKR95Exxpa/ASsjx67A9bLi99Nx+q8CCd+/xw0NuB047Ep/gsIW7Y+D+tdXbgx97yuDjpWtYrTqBMTebxDib+ueIDHmr8Yvz8LWpvpWId3DcH67AxOo87rxk3szcwaOvB1iaezsF4o8nPs6VkI68NHBuk+Y2N5WO/txUlxL2KVxEwZX2OL4/uoGuBnlplZKoPnkhRp1l85NkrHMh8nt+eRBveVUoUOFXH6+NDH9+ciIiL/f9KEKSIi4kATpoiIiANNmCIiIg40YYqIiDiI7CWbXd4FN04P8ARTM2nbN32caaRILKQ2xHtPeoYTXCHpVxknf29mdAtrJhpE9MT0zsEXJnwM1xPGL2Q1jkPP6SzfpzKO37A4OZlKRK/QxNU4vVb/D5w2jJOEnJlZNYmPk1iHz6X2LO8XGSMn4zeSkPg9fKze63Bf3n1bt8z5XrJ3/vQX8OINHB6j+/zgJz+C9bCK053ZBt6XtlrFPahLRdznNR7x/3z/Ypwg/au/uQrW1yzk6ebnH3ka1h98+RCsj8/wPqet7TglOzqK+5+mmnB61sxs9dqVsP6zW/F7YmaWjOE06vKlS2G9UuEp3bCGn3RNafwex1K8B3MqjT8eRw/thPWDB/bSsYqk/+1b3n45rJcK+NqbmS3o6YL1f/nMP6iXrIiIyJ9KE6aIiIgDTZgiIiIONGGKiIg40IQpIiLiQBOmiIiIg8jm65+9ZB6s/+jLfFnJnvA6WJ8Mvg3r5+EUtJmZ7SA9c4MhHEMfDXhj8ibyr0HWx9HpXLCIjvV0gOPm1ybwcoTdHl+iUn0cj/Vk6QRY72vA525mdhpZ8LIm/3d0n0+V8PvypnZ8nO4KXhpgZtb308dh/WvDF8B6f/8kHeu0Gr6Wl77wSVg/d+gWOtb1J+Em0suK+Oarv/cGOtbSN+6m2+a6QrGAN/j8/+YL33YxrAcV3Mw7RpaOmJkFdfyehjG87CoWT9Kx0o24cf9wHt+30/lddKzxIn7NXjoN6zu28CUPx57Cz8Yli/Hn+fRly+lYFdKYPZPkyzfCKn5osibvfoxPAQFZKFUMyFK0On/vF/XhH2AozeAf61id5c/yZ597AdaPHMBLVIqz+F41MwsLE3Qbom+YIiIiDjRhioiIONCEKSIi4kATpoiIiANNmCIiIg4iU7K3p/bB+osX8X1qv70V1v8thhNvz4ckChsJN/+9lIfHqDLpfXwwf5juc56PG4DvJO3XPS+i83y4GJbPasCJs5BF18xsSxof57ni1+g+v87gBGk+ho+zL4g4l9pZsPx4Lz6Xis/P5fkUTuI9P/tZWO/o4UnkmR78f+H2rjysJ4a+TMc6YXQd3TbXNTbhz2BLxFva3LkC1stl3FA/HfE/eNLDxw8z+POcauAp2aCEG2pPT0/BeqyBNznvWpqD9aUNuCn9rgGekjUPJ34TjfjhdHjoIB2qvQM3cu/obKP7lAs4EVoq40T67Axvvl4uTMN6tYzT1vE0Ti6bmc3r7YT1/UdGYH3k4B46VmkGn8uebVtgvb0dH9vMLGzl1xLRN0wREREHmjBFREQcaMIUERFxoAlTRETEgSZMERERB5Ep2dum1sD6yQ8N0n36Nh+F9U8/hhNU1RjvP/i7D/wc1v/t2XfD+ndfytGxvp3E6bFq92WwfkL5NjrWV4dxD9Jf5nBS8/GO++lY+fAcWL/qj5th/WcrcB9FM7PZhq/AuhdeT/dp2Il75oZLcBJtUfZhOtb9wSmw/pl7r4b1L593Ox0rmf4qrA+Rc3njw/heNTM7eN4QrK/vvA/Wn1mI3xMzsw0bzqDb5rrCNOmnGvD/mxMevtdHRvD9sXv7fjpWOo7TsMmWHKx3dOGUqJlZb0cLrMdJX9z2lnY6Fmlxa6Ui7jM6r4snbvt6ceryyPAwrO/cuZ2OtbhC+q+WcELZzGx6Og/rhQI+/tQkThWbmZULOIlcr+B+vbEU7/+6bRtOqlZI2rqrC/cxNzPrO3kt3qcT79PR2U3HSke8ZkTfMEVERBxowhQREXGgCVNERMSBJkwREREHmjBFREQcaMIUERFxELms5D3NeJmA9wPeMDg5D0d7ly/OwXrn3w3QsWqv3ATrDT/FkfL1y9J0LPtLHF8uzTwI67Ef4Di9mVnzOtwU+gOfwHFrewwvXTEzi30Px5rvfuNOWK9eQzLwZhbs/QTe8HV+XVKb8rBevJk0ZX78fDqW933cYPqyC+6B9fr1vOu3vwefS/AVfO2H3oUbZZuZzX4ev/cP//4vYD35Gd7Ff+zb+Lr8Pd1j7ggq+LX7Ef83x6u4mXg2ge/D555+lI41PILfIy+Br/cZZ5xKx9q8EW+bnMTLXba+8Cwda7aEr8vOA/g5t2//fjpWsYAbk4ch/qGBdJY3Bp+aws3Ppyci7vUpvBSG/cxBnPzIgplZSzNeCti7GP9gRFtHLx2rqxcv7ehdj5eItGX5co9kDN+TMVJnDfHNzCw8vu+M+oYpIiLiQBOmiIiIA02YIiIiDjRhioiIONCEKSIi4sALQ55UFBERkdfoG6aIiIgDTZgiIiIONGGKiIg40IQpIiLiQBOmiIiIA02YIiIiDv4PMV6f2j9VR/wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_test = torch.rand(1000, gen.z_len).cuda()\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "best_idx = torch.argmax(dis(gen(z_test))).item()\n",
    "plot_image(gen(z_test)[0], ax[0])\n",
    "plot_image(train_set[1][0], ax[1])\n",
    "\n",
    "print(f\"Fake images discriminator:\\n{dis(gen(z_test[:10]))}\\n\")\n",
    "print(f\"Real images discriminator:\\n{dis(train_set[:10][0].cuda())}\\n\")\n",
    "print(f\"Possible labels: {[label.decode('ascii') for label in cifar_meta[b'label_names']]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Generated Images\n",
    "\n",
    "The main metric we use to evaluate how closely the generated images reflect the training set is the *Frechet inception distance.*  This is a distance metric which compares statistics of samples drawn from the $P_{model}$ and $P_{real}$ distributions.  For corresponding sets of samples $\\{x^{(1)}_{model}, ..., x^{(N)}_{model}\\}$ and $\\{x^{(1)}_{real}, ..., x^{(N)}_{real}\\}$, each $x^{(i)}$ is projected into a 2048-dimensional feature space by running a forward pass through an <a href=\"https://arxiv.org/pdf/1512.00567.pdf\">Inception v3</a> convolutional net pre-trained on the ImageNet dataset, which here is acting essentially as an autoencoder.  This network maps tensors of size $(N, 3, 299, 299) -> (N, 1, 1, 100)$.  So the CIFAR-10 images have to first be zero-padded to the $(299, 299)$ ImageNet size, and then we have to slightly modify the model to output the penultimate layer of size $(N, 1, 1, 2048)$.\n",
    "\n",
    "These embedded vectors are assumed to obey some multivariate Gaussian distribution, such that $x^{(i)}_{emb, model} \\overset{\\text{iid}}{\\sim} \\mathcal{N}_{2048}(\\mu_1, \\Sigma_1)$ and $x^{(i)}_{emb, real} \\overset{\\text{iid}}{\\sim} \\mathcal{N}_{2048}(\\mu_2, \\Sigma_2)$.  Then, the FID is the statistical Frechet distance between these two vectors:\n",
    "$$ FID = ||\\mu_1 - \\mu_2||^2_2 + tr[\\Sigma_1 + \\Sigma_2 - 2(\\Sigma_1 \\Sigma_2)^{1/2}] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "iv3 = inception_v3(pretrained=True, aux_logits=False)\n",
    "# Remove the final layer from the forward pass\n",
    "iv3.fc = nn.Identity()\n",
    "\n",
    "# FID runs considerably faster if this is loaded on GPU\n",
    "if torch.cuda.is_available():\n",
    "    iv3.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_fid(fake_set, real_set, num_samples=1000, batch_size=128):\n",
    "    \"\"\"Calculates the Frechet Inception Distance (FID) between two empirical distributions.\n",
    "       Both `fake_set` and `real_set` should be CIFARDatasets which can be data loaded.\n",
    "       Computes distance over min{`num_samples`, min{len(fake_set), len(real_set)}}\n",
    "       random samples drawn from respective datasets.\"\"\"\n",
    "    \n",
    "    min_len = min(len(fake_set), len(real_set))\n",
    "    num_samples = min(num_samples, min_len)\n",
    "    random_idx = torch.randperm(min_len)[:num_samples]\n",
    "    \n",
    "    padding = nn.ZeroPad2d((133, 134, 133, 134))\n",
    "    fake_embed = torch.empty(num_samples, 2048)\n",
    "    real_embed = torch.empty(num_samples, 2048)\n",
    "    \n",
    "    device = iv3.Conv2d_1a_3x3.conv.weight.device\n",
    "    \n",
    "    for dataset, embed in zip([fake_set, real_set], [fake_embed, real_embed]):\n",
    "        loader = torch.utils.data.DataLoader(CIFARDataset(*dataset[random_idx]), batch_size)\n",
    "        \n",
    "        # Run the encoding in batches to avoid memory overload\n",
    "        for batch_num, (samples, _) in enumerate(loader):\n",
    "            # Necessary to stop gradients from accumulating in iv3 forward passes\n",
    "            with torch.no_grad():\n",
    "                samples = samples.to(device)\n",
    "                # Pad from (N, 3, 32, 32) -> (N, 3, 299, 299)\n",
    "                embedded = iv3(padding(samples))\n",
    "                samples = samples.cpu()\n",
    "                embed[batch_num*batch_size:(batch_num+1)*batch_size, :] = embedded   \n",
    "    \n",
    "    # Calculate empirical statistics of embedded spaces\n",
    "    fake_mean = torch.mean(fake_embed, dim=0)\n",
    "    real_mean = torch.mean(real_embed, dim=0)\n",
    "    fake_cov = torch.tensor(np.cov(fake_embed.T))\n",
    "    real_cov = torch.tensor(np.cov(real_embed.T))\n",
    "    \n",
    "    return (torch.norm(fake_mean - real_mean)**2 +\n",
    "            torch.trace(\n",
    "                fake_cov + real_cov -\n",
    "                2 * torch.tensor(sqrtm(fake_cov @ real_cov), dtype=torch.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.48 s\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    %time fid = calc_fid(train_set, test_set, num_samples=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
