{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN Implementation\n",
    "\n",
    "Implementation of the (vanilla) Deep Convolutional Generative Adversarial Network defined by <a href=\"https://arxiv.org/pdf/1511.06434.pdf\">Radford, Metz, and Chintala (2016)</a>.  Testing is done on the <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">CIFAR-10</a> benchmark image dataset, stored in pickled format in the `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to convert CIFAR-10 to Pytorch Dataset\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as in_file:\n",
    "        pickle_dict = pickle.load(in_file, encoding='bytes')\n",
    "    return pickle_dict\n",
    "\n",
    "\n",
    "def read_data(file_name):\n",
    "    \"\"\"Given path to CIFAR data batch, returns raw X, y tensors.\"\"\"\n",
    "    \n",
    "    batch_dict = unpickle(file_name)\n",
    "    X_raw = torch.tensor(batch_dict[b'data'])\n",
    "    y_raw = torch.tensor(batch_dict[b'labels']).long()\n",
    "    return X_raw, y_raw\n",
    "\n",
    "\n",
    "def shape_image(X):\n",
    "    \"\"\"Reshapes raw data tensor to nn.module-compatible RGB image\"\"\"\n",
    "    \n",
    "    # Each row of X_raw contains RGB color channels concatenated in row-major order\n",
    "    # Need to first split channels into dim 1 on tensor, then shape dim 2/3 into image\n",
    "    image_size = 32*32\n",
    "    X = torch.split(X.unsqueeze(dim=1), image_size, dim=2)\n",
    "    X = torch.cat(X, dim=1)\n",
    "    X = X.view(-1, 3, 32, 32)   # (N, channels, pixel rows, pixel cols)\n",
    "    return X\n",
    "\n",
    "\n",
    "def normalize(X, a=-1, b=1):\n",
    "    \"\"\"Normalizes data tensor to [a, b] using min-max scaling.\"\"\"\n",
    "    \n",
    "    data_min = torch.min(X).float().item()\n",
    "    data_max = torch.max(X).float().item()\n",
    "    assert a < b, \"Rescaled range [a, b] must have a < b\"\n",
    "    \n",
    "    # First scale to [0, 1], then rescale to [a, b]\n",
    "    X = (X - data_min) / (data_max - data_min)\n",
    "    X = (X * (b - a)) + a  \n",
    "    return X\n",
    "\n",
    "\n",
    "class CIFARDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Custom Dataset class which preprocesses and stores datasets\n",
    "       from CIFAR batch files.  Works for CIFAR-10 and CIFAR-100.\"\"\"\n",
    "    \n",
    "    def __init__(self, X=None, y=None):\n",
    "        self.data = X\n",
    "        self.labels = y\n",
    "        \n",
    "    def load(self, file_list):\n",
    "        # Get list of (X, y) tuples, concatenate corresponding tensors\n",
    "        combined_list = [read_data(file_name) for file_name in file_list]\n",
    "        X_list, y_list = list(zip(*combined_list))\n",
    "        X = torch.cat(X_list, dim=0)\n",
    "        y = torch.cat(y_list, dim=0)\n",
    "        \n",
    "        self.data = normalize(shape_image(X))\n",
    "        self.labels = y\n",
    "        return self\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Generates an (X, y) pair at given index\n",
    "        return self.data[index], self.labels[index]\n",
    "    \n",
    "    def cuda(self):\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            self.data = self.data.to(device)\n",
    "            self.labels = self.labels.to(device)\n",
    "            \n",
    "    def cpu(self):\n",
    "        self.data = self.data.cpu()\n",
    "        self.labels = self.labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = CIFARDataset().load([f\"data/data_batch_{n}\" for n in range(1, 6)])\n",
    "test_set = CIFARDataset().load([\"data/test_batch\"])\n",
    "cifar_meta = unpickle(\"data/batches.meta\")\n",
    "\n",
    "# Visualize a few random examples\n",
    "def plot_image(x, ax):\n",
    "    \"\"\"Helper to scale and plot output from ImageDataset.\"\"\"\n",
    "    image = (x.squeeze().permute(1, 2, 0) + 1) / 2\n",
    "    ax.imshow(image.clone().cpu().detach())\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for i in range(3):\n",
    "    X, y = train_set[i*1000]\n",
    "    plot_image(X, ax[i])\n",
    "    ax[i].set_title(cifar_meta[b'label_names'][y.item()].decode('ascii'))\n",
    "plt.suptitle(\"CIFAR-10 sample images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define architecture for vanilla generator and discriminator\n",
    "# See also: https://gluon.mxnet.io/chapter14_generative-adversarial-networks/dcgan.html\n",
    "# https://github.com/soumith/ganhacks\n",
    "\n",
    "def conv_block(which_model, conv_args=[], conv_kwargs={'bias': False},\n",
    "               leak_slope=0.02, batch_norm=True, activation=True):\n",
    "    \"\"\"Performs all the operations in a single DCGAN layer in the following order:\n",
    "       batch normalization -> convolution (optional) -> nonlinearity (optional)\n",
    "       \n",
    "       If which == 'gen', does a transpose convolution\n",
    "       If which == 'dis', does a normal convolution\n",
    "       Returns a list of functions in order; should unpack and fill in nn.Sequential\"\"\"\n",
    "    \n",
    "    funcs = []\n",
    "    \n",
    "    if which_model == 'gen':\n",
    "        funcs.append(nn.ConvTranspose2d(*conv_args, **conv_kwargs))\n",
    "        if batch_norm:\n",
    "            funcs.append(nn.BatchNorm2d(conv_args[1], affine=False))\n",
    "        if activation:\n",
    "            funcs.append(nn.ReLU())\n",
    "            \n",
    "    elif which_model == 'dis':\n",
    "        funcs.append(nn.Conv2d(*conv_args, **conv_kwargs))\n",
    "        if batch_norm:\n",
    "            funcs.append(nn.BatchNorm2d(conv_args[1], affine=False))\n",
    "        if activation:\n",
    "            funcs.append(nn.LeakyReLU(leak_slope))\n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Argument `which_model` is not a valid value\")\n",
    "        \n",
    "    # Initialize the weights to match DCGAN paper?\n",
    "    # Build a list of the three functions in sequence\n",
    "    return funcs\n",
    "    \n",
    "\n",
    "class DCGenerator(nn.Module):\n",
    "    \"\"\"Deep convolutional generator which maps latent noise vector -> (32,32) RGB-channel image.\n",
    "       The latent space input z is projected and convolved with many feature maps.\n",
    "       Subsequent layers use only fractional-strided convolutions (no pooling).\n",
    "       All hidden layers use ReLU activation, and output layer uses tanh.\"\"\"\n",
    "    \n",
    "    def __init__(self, z_len=128):\n",
    "        \n",
    "        super(DCGenerator, self).__init__()\n",
    "        self.z_len = z_len\n",
    "        \n",
    "        self.in_layer = nn.Linear(z_len, 128 * 4 * 4)\n",
    "        \n",
    "        # Choose kernel_size, stride, padding to double height/width for each layer\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            #*conv_block('gen', [z_len, 128, 4, 1, 0]),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            *conv_block('gen', [128, 128, 4, 2, 1]),\n",
    "            *conv_block('gen', [128, 128, 4, 2, 1]),\n",
    "            *conv_block('gen', [128, 3, 4, 2, 1], batch_norm=False, activation=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        # Reshape z as 4d tensor, with latent code vector along channel dimension\n",
    "        z = self.in_layer(z).view(-1, 128, 4, 4)\n",
    "        return self.conv_layers(z)\n",
    "\n",
    "\n",
    "class DCDiscriminator(nn.Module):\n",
    "    \"\"\"Deep convolutional discriminator which maps (32,32) RGB-channel image -> [0, 1].\n",
    "       The image is passed through several convolutional layers (again, no pooling).\n",
    "       All hidden layers use LeakyReLU activation, and output layer uses sigmoid.\"\"\"\n",
    "    \n",
    "    def __init__(self, leak_slope=0.02):\n",
    "        \n",
    "        super(DCDiscriminator, self).__init__()\n",
    "        \n",
    "        # Just reverse the convolutional layers from the Generator\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            *conv_block('dis', [3, 128, 4, 2, 1], batch_norm=False),\n",
    "            *conv_block('dis', [128, 128, 4, 2, 1]),\n",
    "            *conv_block('dis', [128, 128, 4, 2, 1])\n",
    "        )\n",
    "        \n",
    "        self.out_layer = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        # Reshape discriminator output by flattening, then feed into sigmoid activation\n",
    "        x = x.view(-1, torch.prod(torch.tensor(x.shape[1:])))\n",
    "        return self.out_layer(x)\n",
    "        #return torch.sigmoid(self.out_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = DCGenerator()\n",
    "dis = DCDiscriminator()\n",
    "z_test = torch.rand(5, 128)\n",
    "dis(gen(z_test)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN Training\n",
    "\n",
    "The training is done using the minimax game described in the original GAN paper by <a href=\"https://arxiv.org/pdf/1406.2661.pdf\">Goodfellow, et al (2014)</a>.  The choice of optimizer and batch size are specific to the DCGAN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to train built models and evaluate convergence\n",
    "\n",
    "def jensen_shannon(which_model, device):\n",
    "    \"\"\"Returns a function to compute an empirical estimate of the Jensen-Shannon\n",
    "       divergence between the true data-generating distribution P_real and\n",
    "       the generated distribution P_model over parallel batches x_real and x_model.\n",
    "       \n",
    "       This metric is optimized by a minimax operation, first maximizing over the\n",
    "       discriminator weights, then minimizing over the generator weights.\n",
    "       \n",
    "       Returns:\n",
    "       - if which_model = 'dis': returns function (D(x_model), D(x_real)) -> scalar\n",
    "       - if which_model = 'gen': returns function (D(x_model)) -> scalar\n",
    "         Both functions are returned in the form of minimization problems.\n",
    "       - if which_model = 'full': returns non-negative version of 'dis' function.\n",
    "         Use this version to calculate divergence after an epoch.\"\"\"\n",
    "    \n",
    "    if which_model == 'dis':\n",
    "        #return lambda dis_model, dis_real: \\\n",
    "            #-torch.mean(torch.log(dis_real) + torch.log(1 - dis_model))\n",
    "        bce = nn.BCELoss()\n",
    "        model_loss = lambda d_model: \\\n",
    "            bce(d_model, torch.zeros(d_model.size()).to(device))\n",
    "        real_loss = lambda d_real: \\\n",
    "            bce(d_real, torch.ones(d_real.size()).to(device))\n",
    "        return lambda d_model, d_real: \\\n",
    "            model_loss(d_model) + real_loss(d_real)\n",
    "        \n",
    "    elif which_model == 'gen':\n",
    "        # If generated samples are rejected easily, log(1 - D(x_model)) saturates\n",
    "        # (stays close to 0), so use an approximation to improve early training\n",
    "        #return lambda dis_model: \\\n",
    "            #-torch.mean(torch.log(dis_model))\n",
    "        bce = nn.BCELoss()\n",
    "        return lambda d_model: \\\n",
    "            bce(d_model, torch.ones(d_model.size()).to(device))\n",
    "    \n",
    "    elif which_model == 'full':\n",
    "        return lambda dis_model, dis_real: \\\n",
    "            torch.mean(torch.log(dis_real) + torch.log(1 - dis_model))\n",
    "   \n",
    "    else:\n",
    "        raise ValueError(\"Argument `which_model` is not a valid value\")\n",
    "\n",
    "        \n",
    "def train_DCGAN(gen, dis, train_set, test_set,\n",
    "                num_epochs=100, dg_ratio=1, batch_size=128,\n",
    "                use_cuda=True):\n",
    "    \"\"\"Simultaneously trains generator and discriminator using minimax optimization of\n",
    "       Jensen-Shannon divergence between discriminator performance on x_real vs. x_model.\n",
    "       Uses ADAM optimizer for both networks, using params defined in DCGAN paper.\n",
    "       Latent codes Z are drawn from a uniform prior.\n",
    "       \n",
    "       Parameters\n",
    "       - num_epochs: the number of training epochs over the dataset\n",
    "       - dg_ratio: the ratio of discriminator batches to generator batches\n",
    "       - batch_size: the train_set batch size passed into discriminator\n",
    "                     (for each real batch, an equal-sized batch is generated by generator)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move to GPU if possible; batches get moved as needed to save on memory\n",
    "    device = \"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    criterion_dis = jensen_shannon(\"dis\", device)\n",
    "    criterion_gen = jensen_shannon(\"gen\", device)\n",
    "    optimizer_dis = torch.optim.Adam(dis.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "    # Keep a global count of how many discriminator steps happen per generator step\n",
    "    # because dg_ratio may not divide evenly into batch_size\n",
    "    dis_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        #print(f\"EPOCH {epoch+1}\")\n",
    "        \n",
    "        for X, y in loader:\n",
    "            z = torch.rand((X.shape[0], gen.z_len)).to(device)\n",
    "            X = X.clone().to(device, non_blocking=True)\n",
    "            \n",
    "            # Discriminator trains each batch\n",
    "            optimizer_dis.zero_grad()\n",
    "            loss_dis = criterion_dis(dis(gen(z)), dis(X))\n",
    "            loss_dis.backward()\n",
    "            optimizer_dis.step()\n",
    "            dis_count += 1\n",
    "            \n",
    "            # Generator trains if enough discriminator passes have gone through\n",
    "            if dis_count >= dg_ratio:\n",
    "                z = torch.rand((batch_size, gen.z_len)).to(device)\n",
    "                optimizer_gen.zero_grad()\n",
    "                loss_gen = criterion_gen(dis(gen(z)))\n",
    "                loss_gen.backward()\n",
    "                optimizer_gen.step()\n",
    "                dis_count = 0\n",
    " \n",
    "        # Evaluate how the model is performing on test set after a full epoch\n",
    "        print(f\"- EPOCH {epoch+1}:\" +\n",
    "              f\"\\n  discriminator loss = {loss_dis}\" +\n",
    "              f\"\\n      generator loss = {loss_gen}\" +\n",
    "              \"\\n----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible function if we need more abstraction in sampling from the noise\n",
    "# (if it gets more complex than uniform vs. normal)\n",
    "def generate_noise(curr_batch_size, latent_dim, distribution, device):\n",
    "    pass\n",
    "\n",
    "def compute_wasserstein_loss(which_model, d_real, d_model, device, lambda_=10):\n",
    "    \"\"\"Returns a function to compute an empirical estimate of the Wasserstein\n",
    "       loss between the true data-generating distribution P_real and\n",
    "       the generated distribution P_model over parallel batches x_real and x_model.\n",
    "       \n",
    "       This metric is optimized by a minimax operation, first maximizing over the\n",
    "       discriminator weights, then minimizing over the generator weights.\n",
    "       \n",
    "       Returns:\n",
    "       - if which_model = 'dis': returns function (D(x_model), D(x_real)) -> scalar\n",
    "       - if which_model = 'gen': returns function (D(x_model)) -> scalar\n",
    "         Both functions are returned in the form of minimization problems.\"\"\"\n",
    "    \n",
    "    if which_model == 'dis':\n",
    "        return - torch.mean(d_real - d_model).to(device)\n",
    "    elif which_model == 'gen':\n",
    "        return - torch.mean(d_model).to(device)\n",
    "    else: \n",
    "        raise ValueError(\"Argument `which_model` is not a valid value\")\n",
    "        \n",
    "def compute_wasserstein_gen_loss(d_model, device, lambda_=10):\n",
    "    return - torch.mean(d_model).to(device)\n",
    "        \n",
    "        \n",
    "def clip_weights(model, clip):\n",
    "    for param in model.parameters():\n",
    "        param.data.clamp_(-clip, clip)\n",
    "\n",
    "# NOTES:\n",
    "# - WGAN uses RMSProp\n",
    "def train_WGAN(gen, dis, train_set, test_set, \n",
    "               num_epochs=100, ncritic=5, batch_size=64, \n",
    "               lr=0.00005, use_cuda=True):\n",
    "    \n",
    "    \"\"\"Simultaneously trains generator and discriminator using minimax optimizatinon of\n",
    "       an estimate of the Earth-Mover/Wasserstein loss induced by weight clipping\n",
    "       between the the true distribution and the model's distribution.\n",
    "       \n",
    "       Parameters\n",
    "       - num_epochs: the number of training epochs over the dataset\n",
    "       - dg_ratio: the ratio of discriminator batches to generator batches\n",
    "       - batch_size: the train_set batch size passed into discriminator\n",
    "                     (for each real batch, an equal-sized batch is generated by generator)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move to GPU if possible; batches get moved as needed to save on memory\n",
    "    device = \"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    optimizer_dis = torch.optim.RMSprop(dis.parameters(), lr=lr)\n",
    "    optimizer_gen = torch.optim.RMSprop(gen.parameters(), lr=lr)\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "    \n",
    "    # Keep a global count of how many discriminator steps happen per generator step\n",
    "    # because dg_ratio may not divide evenly into batch_size\n",
    "    for epoch in range(num_epochs):\n",
    "        #print(f\"EPOCH {epoch+1}\")\n",
    "        \n",
    "        for i, (X, y) in enumerate(loader):\n",
    "            optimizer_dis.zero_grad()\n",
    "            \n",
    "            # Sample real data and noise\n",
    "            z = torch.randn((X.shape[0], gen.z_len)).to(device)\n",
    "            X = X.clone().to(device, non_blocking=True)\n",
    "            \n",
    "            # Info related to \"Improved WGAN\" training - not implementing for now\n",
    "            # epsilon = np.random.uniform()\n",
    "            # fake_images = gen(z)\n",
    "            # X_hat = epsilon * X + (1 - epsilon) * fake_images\n",
    "            # d_real, d_model = dis(X), dis(X_hat)\n",
    "            \n",
    "            # Pass real and fake data through the discriminator, and take a discriminator step\n",
    "            d_real, d_model = dis(X), dis(gen(z))\n",
    "            loss_dis = compute_wasserstein_loss('dis', d_real=d_real, d_model=d_model, device=device)\n",
    "            loss_dis.backward()\n",
    "            optimizer_dis.step()\n",
    "            \n",
    "            # Clip the weights of the discriminator to enfore Lipschitz continuity\n",
    "            clip_weights(dis, 0.01)\n",
    "            \n",
    "            # Generator trains if enough discriminator passes have gone through\n",
    "            if i % ncritic == 0:\n",
    "                optimizer_gen.zero_grad()\n",
    "                z = torch.randn((batch_size, gen.z_len)).to(device)\n",
    "                d_model = dis(gen(z))\n",
    "                loss_gen = compute_wasserstein_gen_loss(d_model=d_model, device=device)\n",
    "                loss_gen.backward()\n",
    "                optimizer_gen.step()\n",
    " \n",
    "        # Evaluate how the model is performing on test set after a full epoch\n",
    "        print(f\"- EPOCH {epoch+1}:\" +\n",
    "              f\"\\n  discriminator loss = {loss_dis}\" +\n",
    "              f\"\\n      generator loss = {loss_gen}\" +\n",
    "              \"\\n----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DCGenerator().cuda()\n",
    "dis = DCDiscriminator().cuda()\n",
    "train_set = CIFARDataset().load([f\"data/data_batch_{n}\" for n in range(1, 2)])\n",
    "test_set = CIFARDataset().load([\"data/test_batch\"])\n",
    "dis.out_layer[3] = nn.Identity()  # Remove the sigmoid function for WGAN\n",
    "train_WGAN(gen, dis, train_set, test_set, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_improved_WGAN(gen, dis, train_set, test_set, \n",
    "                        num_epochs=100, ncritic=5, batch_size=64, \n",
    "                        lr=0.0001, lambda_=10, use_cuda=True):\n",
    "    \n",
    "    \"\"\"Simultaneously trains generator and discriminator using minimax optimizatinon of\n",
    "       an estimate of the Earth-Mover/Wasserstein loss induced by weight clipping\n",
    "       between the the true distribution and the model's distribution.\n",
    "       \n",
    "       Parameters\n",
    "       - num_epochs: the number of training epochs over the dataset\n",
    "       - dg_ratio: the ratio of discriminator batches to generator batches\n",
    "       - batch_size: the train_set batch size passed into discriminator\n",
    "                     (for each real batch, an equal-sized batch is generated by generator)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move to GPU if possible; batches get moved as needed to save on memory\n",
    "    device = \"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    optimizer_dis = torch.optim.Adam(dis.parameters(), lr=lr, betas=(0, 0.9))\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=lr, betas=(0, 0.9))\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "    \n",
    "    # Keep a global count of how many discriminator steps happen per generator step\n",
    "    # because dg_ratio may not divide evenly into batch_size\n",
    "    for epoch in range(num_epochs):\n",
    "        #print(f\"EPOCH {epoch+1}\")\n",
    "        \n",
    "        for i, (X, y) in enumerate(loader):\n",
    "            optimizer_dis.zero_grad()\n",
    "            \n",
    "            # Sample real data and noise\n",
    "            z = torch.randn((X.shape[0], gen.z_len)).to(device)\n",
    "            X = X.clone().to(device, non_blocking=True)\n",
    "            \n",
    "            # Info related to \"Improved WGAN\" training - not implementing for now\n",
    "            epsilon = np.random.uniform()\n",
    "            X_tilde = gen(z)\n",
    "            X_hat = epsilon * X + (1 - epsilon) * X_tilde\n",
    "            X_hat_dis = dis(X_hat)\n",
    "            grad_penalty = torch.autograd.grad(outputs=X_hat_dis, inputs=X_hat, grad_outputs=torch.ones_like(X_hat_dis))\n",
    "            \n",
    "            # Pass real and fake data through the discriminator, and take a discriminator step\n",
    "            d_real, d_model = dis(X), dis(X_tilde)\n",
    "            loss_dis = compute_wasserstein_loss('dis', d_real=d_real, d_model=d_model, device=device)\n",
    "\n",
    "            loss_dis += lambda_ * (grad_penalty[0].norm() - 1) ** 2\n",
    "            loss_dis.backward()\n",
    "            optimizer_dis.step()\n",
    "            \n",
    "            # Generator trains if enough discriminator passes have gone through\n",
    "            if i % ncritic == 0:\n",
    "                optimizer_gen.zero_grad()\n",
    "                z = torch.randn((batch_size, gen.z_len)).to(device)\n",
    "                d_model = dis(gen(z))\n",
    "                loss_gen = compute_wasserstein_gen_loss(d_model=d_model, device=device)\n",
    "                loss_gen.backward()\n",
    "                optimizer_gen.step()\n",
    " \n",
    "        # Evaluate how the model is performing on test set after a full epoch\n",
    "        print(f\"- EPOCH {epoch+1}:\" +\n",
    "              f\"\\n  discriminator loss = {loss_dis}\" +\n",
    "              f\"\\n      generator loss = {loss_gen}\" +\n",
    "              \"\\n----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- EPOCH 1:\n",
      "  discriminator loss = 205365.546875\n",
      "      generator loss = 695.232177734375\n",
      "----------------------------------\n",
      "- EPOCH 2:\n",
      "  discriminator loss = 4586196.0\n",
      "      generator loss = 2247.521728515625\n",
      "----------------------------------\n",
      "- EPOCH 3:\n",
      "  discriminator loss = 129304568.0\n",
      "      generator loss = 4602.564453125\n",
      "----------------------------------\n",
      "- EPOCH 4:\n",
      "  discriminator loss = 1136536576.0\n",
      "      generator loss = 7896.546875\n",
      "----------------------------------\n",
      "- EPOCH 5:\n",
      "  discriminator loss = 28114092032.0\n",
      "      generator loss = 11775.40234375\n",
      "----------------------------------\n",
      "- EPOCH 6:\n",
      "  discriminator loss = 154791504.0\n",
      "      generator loss = 16835.62890625\n",
      "----------------------------------\n",
      "- EPOCH 7:\n",
      "  discriminator loss = 136866471936.0\n",
      "      generator loss = 22605.603515625\n",
      "----------------------------------\n",
      "- EPOCH 8:\n",
      "  discriminator loss = 4113101568.0\n",
      "      generator loss = 29284.58984375\n",
      "----------------------------------\n",
      "- EPOCH 9:\n",
      "  discriminator loss = 2180821248.0\n",
      "      generator loss = 36638.625\n",
      "----------------------------------\n",
      "- EPOCH 10:\n",
      "  discriminator loss = 82979815424.0\n",
      "      generator loss = 44962.7421875\n",
      "----------------------------------\n",
      "- EPOCH 11:\n",
      "  discriminator loss = 522786528.0\n",
      "      generator loss = 54211.92578125\n",
      "----------------------------------\n",
      "- EPOCH 12:\n",
      "  discriminator loss = 169529504.0\n",
      "      generator loss = 64057.3203125\n",
      "----------------------------------\n",
      "- EPOCH 13:\n",
      "  discriminator loss = 154710360064.0\n",
      "      generator loss = 74740.046875\n",
      "----------------------------------\n",
      "- EPOCH 14:\n",
      "  discriminator loss = 124481167360.0\n",
      "      generator loss = 86382.171875\n",
      "----------------------------------\n",
      "- EPOCH 15:\n",
      "  discriminator loss = 308375680.0\n",
      "      generator loss = 99265.671875\n",
      "----------------------------------\n",
      "- EPOCH 16:\n",
      "  discriminator loss = 3308325699584.0\n",
      "      generator loss = 112656.5859375\n",
      "----------------------------------\n",
      "- EPOCH 17:\n",
      "  discriminator loss = 80329503145984.0\n",
      "      generator loss = 125221.078125\n",
      "----------------------------------\n",
      "- EPOCH 18:\n",
      "  discriminator loss = 8050479616.0\n",
      "      generator loss = 141480.5\n",
      "----------------------------------\n",
      "- EPOCH 19:\n",
      "  discriminator loss = 12048891904.0\n",
      "      generator loss = 156315.25\n",
      "----------------------------------\n",
      "- EPOCH 20:\n",
      "  discriminator loss = 974492800.0\n",
      "      generator loss = 174695.28125\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "gen = DCGenerator().cuda()\n",
    "dis = DCDiscriminator().cuda()\n",
    "dis.out_layer[3] = nn.Identity()  # Remove the sigmoid function for WGAN\n",
    "train_improved_WGAN(gen, dis, train_set, test_set, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images discriminator:\n",
      "tensor([[-179183.4219],\n",
      "        [-170015.0781],\n",
      "        [-174693.0000],\n",
      "        [-174247.8438],\n",
      "        [-175434.1250],\n",
      "        [-171451.9062],\n",
      "        [-180195.2500],\n",
      "        [-175718.0625],\n",
      "        [-172036.1875],\n",
      "        [-171556.1406]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "\n",
      "Real images discriminator:\n",
      "tensor([[146177.5312],\n",
      "        [139919.9375],\n",
      "        [146374.6562],\n",
      "        [147815.5469],\n",
      "        [144475.2812],\n",
      "        [141564.0000],\n",
      "        [145166.9375],\n",
      "        [143805.3125],\n",
      "        [146779.9375],\n",
      "        [143053.5312]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "\n",
      "Possible labels: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_test = torch.rand(1000, gen.z_len).cuda()\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "best_idx = torch.argmax(dis(gen(z_test))).item()\n",
    "plot_image(gen(z_test)[0], ax[0])\n",
    "plot_image(train_set[1][0], ax[1])\n",
    "\n",
    "print(f\"Fake images discriminator:\\n{dis(gen(z_test[:10]))}\\n\")\n",
    "print(f\"Real images discriminator:\\n{dis(train_set[:10][0].cuda())}\\n\")\n",
    "print(f\"Possible labels: {[label.decode('ascii') for label in cifar_meta[b'label_names']]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Generated Images\n",
    "\n",
    "The main metric we use to evaluate how closely the generated images reflect the training set is the *Frechet inception distance.*  This is a distance metric which compares statistics of samples drawn from the $P_{model}$ and $P_{real}$ distributions.  For corresponding sets of samples $\\{x^{(1)}_{model}, ..., x^{(N)}_{model}\\}$ and $\\{x^{(1)}_{real}, ..., x^{(N)}_{real}\\}$, each $x^{(i)}$ is projected into a 2048-dimensional feature space by running a forward pass through an <a href=\"https://arxiv.org/pdf/1512.00567.pdf\">Inception v3</a> convolutional net pre-trained on the ImageNet dataset, which here is acting essentially as an autoencoder.  This network maps tensors of size $(N, 3, 299, 299) -> (N, 1, 1, 100)$.  So the CIFAR-10 images have to first be zero-padded to the $(299, 299)$ ImageNet size, and then we have to slightly modify the model to output the penultimate layer of size $(N, 1, 1, 2048)$.\n",
    "\n",
    "These embedded vectors are assumed to obey some multivariate Gaussian distribution, such that $x^{(i)}_{emb, model} \\overset{\\text{iid}}{\\sim} \\mathcal{N}_{2048}(\\mu_1, \\Sigma_1)$ and $x^{(i)}_{emb, real} \\overset{\\text{iid}}{\\sim} \\mathcal{N}_{2048}(\\mu_2, \\Sigma_2)$.  Then, the FID is the statistical Frechet distance between these two vectors:\n",
    "$$ FID = ||\\mu_1 - \\mu_2||^2_2 + tr[\\Sigma_1 + \\Sigma_2 - 2(\\Sigma_1 \\Sigma_2)^{1/2}] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "iv3 = inception_v3(pretrained=True, aux_logits=False)\n",
    "# Remove the final layer from the forward pass\n",
    "iv3.fc = nn.Identity()\n",
    "\n",
    "# FID runs considerably faster if this is loaded on GPU\n",
    "if torch.cuda.is_available():\n",
    "    iv3.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fid(fake_set, real_set, num_samples=1000, batch_size=128):\n",
    "    \"\"\"Calculates the Frechet Inception Distance (FID) between two empirical distributions.\n",
    "       Both `fake_set` and `real_set` should be CIFARDatasets which can be data loaded.\n",
    "       Computes distance over min{`num_samples`, min{len(fake_set), len(real_set)}}\n",
    "       random samples drawn from respective datasets.\"\"\"\n",
    "    \n",
    "    min_len = min(len(fake_set), len(real_set))\n",
    "    num_samples = min(num_samples, min_len)\n",
    "    random_idx = torch.randperm(min_len)[:num_samples]\n",
    "    \n",
    "    padding = nn.ZeroPad2d((133, 134, 133, 134))\n",
    "    fake_embed = torch.empty(num_samples, 2048)\n",
    "    real_embed = torch.empty(num_samples, 2048)\n",
    "    \n",
    "    device = iv3.Conv2d_1a_3x3.conv.weight.device\n",
    "    \n",
    "    for dataset, embed in zip([fake_set, real_set], [fake_embed, real_embed]):\n",
    "        loader = torch.utils.data.DataLoader(CIFARDataset(*dataset[random_idx]), batch_size)\n",
    "        \n",
    "        # Run the encoding in batches to avoid memory overload\n",
    "        for batch_num, (samples, _) in enumerate(loader):\n",
    "            # Necessary to stop gradients from accumulating in iv3 forward passes\n",
    "            with torch.no_grad():\n",
    "                samples = samples.to(device)\n",
    "                # Pad from (N, 3, 32, 32) -> (N, 3, 299, 299)\n",
    "                embedded = iv3(padding(samples))\n",
    "                samples = samples.cpu()\n",
    "                embed[batch_num*batch_size:(batch_num+1)*batch_size, :] = embedded   \n",
    "    \n",
    "    # Calculate empirical statistics of embedded spaces\n",
    "    fake_mean = torch.mean(fake_embed, dim=0)\n",
    "    real_mean = torch.mean(real_embed, dim=0)\n",
    "    fake_cov = torch.tensor(np.cov(fake_embed.T))\n",
    "    real_cov = torch.tensor(np.cov(real_embed.T))\n",
    "    \n",
    "    return (torch.norm(fake_mean - real_mean)**2 +\n",
    "            torch.trace(\n",
    "                fake_cov + real_cov -\n",
    "                2 * torch.tensor(sqrtm(fake_cov @ real_cov), dtype=torch.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    %time fid = calc_fid(train_set, test_set, num_samples=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
